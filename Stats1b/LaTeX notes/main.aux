\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\BKM@entry[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\BKM@entry{id=1,dest={73656374696F6E2E31},srcline={1}}{4F76657276696577}
\babel@aux{english}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Overview}{1}{section.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \relax }}{6}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:overview8.1.1}{{1}{6}{\relax }{table.caption.1}{}}
\newlabel{tab:overview8.1.1@cref}{{[table][1][]1}{[1][5][]6}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \relax }}{6}{table.caption.2}\protected@file@percent }
\newlabel{tab:overview8.1.2}{{2}{6}{\relax }{table.caption.2}{}}
\newlabel{tab:overview8.1.2@cref}{{[table][2][]2}{[1][6][]6}}
\BKM@entry{id=2,dest={73656374696F6E2A2E34},srcline={4}}{5765656B2031}
\BKM@entry{id=3,dest={73656374696F6E2A2E36},srcline={8}}{506F776572}
\@writefile{toc}{\contentsline {section}{Week 1}{7}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Power}{7}{section*.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces This graph shows the distribution of the difference in means from the experiment laid out in question 1 of homework 1. In a sample of size 23, we correctly assume that the experimental group has lower test scores than the control group if the difference in sample means is more than 3 at a 5\% significance level. If the true population has a mean of 5 points, then this correct assumption will be reached in 84.6\% of tests.\relax }}{8}{figure.1}\protected@file@percent }
\newlabel{fig:power1}{{1}{8}{This graph shows the distribution of the difference in means from the experiment laid out in question 1 of homework 1. In a sample of size 23, we correctly assume that the experimental group has lower test scores than the control group if the difference in sample means is more than 3 at a 5\% significance level. If the true population has a mean of 5 points, then this correct assumption will be reached in 84.6\% of tests.\relax }{figure.1}{}}
\newlabel{fig:power1@cref}{{[figure][1][]1}{[1][7][]8}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces This graph shows the cut-off values of 3.09 ($n=23$), 2.09 ($n=50$), 1.71 ($n=75$), and 1.48 ($n=100$) for a fixed significance level ($z^*_{1 - \alpha } = 1.645$; $\alpha = 0.05$) for a normally distributed random variable ($\bar  {X} - \bar  {Y}$) with mean zero and standard deviation $9/\sqrt  {n}$. The shaded area under the graph represents the top 5\% of each of the distributions (so the area is the same), however the value for which the top 5\% is taken from is changing. \relax }}{8}{figure.2}\protected@file@percent }
\newlabel{fig:power2}{{2}{8}{This graph shows the cut-off values of 3.09 ($n=23$), 2.09 ($n=50$), 1.71 ($n=75$), and 1.48 ($n=100$) for a fixed significance level ($z^*_{1 - \alpha } = 1.645$; $\alpha = 0.05$) for a normally distributed random variable ($\bar {X} - \bar {Y}$) with mean zero and standard deviation $9/\sqrt {n}$. The shaded area under the graph represents the top 5\% of each of the distributions (so the area is the same), however the value for which the top 5\% is taken from is changing. \relax }{figure.2}{}}
\newlabel{fig:power2@cref}{{[figure][2][]2}{[1][8][]8}}
\BKM@entry{id=4,dest={73656374696F6E2A2E38},srcline={123}}{436F6E666964656E636520496E74657276616C73}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The shaded area represents the power of the test for increasing values of $n$, where the random variable $\bar  {X} - \bar  {Y}$ is distributed normally with standard error $9/\sqrt  {n}$ ($\alpha = 0.05$; $H_0:$ $\mu =0$; $H_a: $ $\mu >0$; true mean $\mu =5$).\relax }}{9}{figure.3}\protected@file@percent }
\newlabel{fig:power3}{{3}{9}{The shaded area represents the power of the test for increasing values of $n$, where the random variable $\bar {X} - \bar {Y}$ is distributed normally with standard error $9/\sqrt {n}$ ($\alpha = 0.05$; $H_0:$ $\mu =0$; $H_a: $ $\mu >0$; true mean $\mu =5$).\relax }{figure.3}{}}
\newlabel{fig:power3@cref}{{[figure][3][]3}{[1][9][]9}}
\@writefile{toc}{\contentsline {subsection}{Confidence Intervals}{9}{section*.8}\protected@file@percent }
\BKM@entry{id=5,dest={73656374696F6E2A2E3130},srcline={166}}{56617269616E636520616E64207374616E6461726420646576696174696F6E}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces In \href  {hw2q1}{question 1 of Homework 2}, the population is distributed normally with mean 53 and standard deviation 7. A sample of 25 is taken, and a mean of 48 is computed from the sample which is useful in constructing a 95\% confidence interval, where the margin of error is $1.96 \times 1.4 = 2.744$. The confidence interval is shaded pink, and the pink dash line is the sampling distribution of the mean centred at 48. The sampling distribution of the mean of $X$ is distributed normally with a mean of 53 and standard deviation of $\sigma /\sqrt  {n} = 7/5 = 1.4$ for a sample size of 25. The black dashed line represents the standard normal distribution centred at 48.\relax }}{10}{figure.4}\protected@file@percent }
\newlabel{fig:CI1}{{4}{10}{In \href {hw2q1}{question 1 of Homework 2}, the population is distributed normally with mean 53 and standard deviation 7. A sample of 25 is taken, and a mean of 48 is computed from the sample which is useful in constructing a 95\% confidence interval, where the margin of error is $1.96 \times 1.4 = 2.744$. The confidence interval is shaded pink, and the pink dash line is the sampling distribution of the mean centred at 48. The sampling distribution of the mean of $X$ is distributed normally with a mean of 53 and standard deviation of $\sigma /\sqrt {n} = 7/5 = 1.4$ for a sample size of 25. The black dashed line represents the standard normal distribution centred at 48.\relax }{figure.4}{}}
\newlabel{fig:CI1@cref}{{[figure][4][]4}{[1][10][]10}}
\@writefile{toc}{\contentsline {subsection}{Variance and standard deviation}{10}{section*.10}\protected@file@percent }
\BKM@entry{id=6,dest={73656374696F6E2A2E3132},srcline={196}}{506F6F6C65642076617269616E6365}
\newlabel{eq:unisd}{{23}{11}{Variance and standard deviation}{equation.1.23}{}}
\newlabel{eq:unisd@cref}{{[equation][23][]23}{[1][11][]11}}
\@writefile{toc}{\contentsline {subsubsection}{Pooled variance}{11}{section*.12}\protected@file@percent }
\newlabel{eq:bisp}{{26}{11}{Pooled variance}{equation.1.26}{}}
\newlabel{eq:bisp@cref}{{[equation][26][]26}{[1][11][]11}}
\BKM@entry{id=7,dest={73656374696F6E2A2E3134},srcline={234}}{556E706F6F6C65642076617269616E6365}
\BKM@entry{id=8,dest={73656374696F6E2A2E3136},srcline={248}}{5061697265642064617461}
\BKM@entry{id=9,dest={73656374696F6E2A2E3138},srcline={3}}{5765656B2033}
\BKM@entry{id=10,dest={73656374696F6E2A2E3230},srcline={7}}{4D6F7265206F6E207072696F726973}
\@writefile{toc}{\contentsline {subsubsection}{Unpooled variance}{13}{section*.14}\protected@file@percent }
\newlabel{eq:bisup}{{43}{13}{Unpooled variance}{equation.1.43}{}}
\newlabel{eq:bisup@cref}{{[equation][43][]43}{[1][13][]13}}
\newlabel{eq:1.2a}{{44}{13}{Unpooled variance}{equation.1.44}{}}
\newlabel{eq:1.2a@cref}{{[equation][44][]44}{[1][13][]13}}
\newlabel{eq:sepooled}{{46}{13}{Unpooled variance}{equation.1.46}{}}
\newlabel{eq:sepooled@cref}{{[equation][46][]46}{[1][13][]13}}
\newlabel{paireddata}{{1}{13}{Paired data}{section*.16}{}}
\newlabel{paireddata@cref}{{[section][1][]1}{[1][13][]13}}
\@writefile{toc}{\contentsline {subsubsection}{Paired data}{13}{section*.16}\protected@file@percent }
\newlabel{eq:meandiffbar}{{47}{13}{Paired data}{equation.1.47}{}}
\newlabel{eq:meandiffbar@cref}{{[equation][47][]47}{[1][13][]13}}
\newlabel{eq:meandiffsd}{{48}{13}{Paired data}{equation.1.48}{}}
\newlabel{eq:meandiffsd@cref}{{[equation][48][]48}{[1][13][]13}}
\@writefile{toc}{\contentsline {section}{Week 3}{14}{section*.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{More on prioris}{14}{section*.20}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \relax }}{14}{table.caption.21}\protected@file@percent }
\newlabel{tab:priori1}{{3}{14}{\relax }{table.caption.21}{}}
\newlabel{tab:priori1@cref}{{[table][3][]3}{[1][14][]14}}
\newlabel{fig:priori1a}{{5a}{15}{Approximately 95\% of sample means lie within 1.96 standard deviations from the mean.\relax }{subfigure.5.1}{}}
\newlabel{fig:priori1a@cref}{{[subfigure][1][5]5a}{[1][15][]15}}
\newlabel{sub@fig:priori1a}{{a}{15}{Approximately 95\% of sample means lie within 1.96 standard deviations from the mean.\relax }{subfigure.5.1}{}}
\newlabel{sub@fig:priori1a@cref}{{[subfigure][1][5]5a}{[1][15][]15}}
\newlabel{fig:priori1b}{{5b}{15}{Approximately 95\% of sample means lie below 1.645 standard deviations above the mean.\relax }{subfigure.5.2}{}}
\newlabel{fig:priori1b@cref}{{[subfigure][2][5]5b}{[1][15][]15}}
\newlabel{sub@fig:priori1b}{{b}{15}{Approximately 95\% of sample means lie below 1.645 standard deviations above the mean.\relax }{subfigure.5.2}{}}
\newlabel{sub@fig:priori1b@cref}{{[subfigure][2][5]5b}{[1][15][]15}}
\newlabel{fig:priori1c}{{5c}{15}{Approximately 95\% of sample means lie above 1.645 standard deviations below the mean.\relax }{subfigure.5.3}{}}
\newlabel{fig:priori1c@cref}{{[subfigure][3][5]5c}{[1][15][]15}}
\newlabel{sub@fig:priori1c}{{c}{15}{Approximately 95\% of sample means lie above 1.645 standard deviations below the mean.\relax }{subfigure.5.3}{}}
\newlabel{sub@fig:priori1c@cref}{{[subfigure][3][5]5c}{[1][15][]15}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces For a given random variable $X$ which has mean $\mu _0$ and standard deviation $\sigma $, the sampling distribution of the mean of size $n$ is Normal with mean $\mu _0$ and standard deviation $\sigma /\sqrt  {n}$ (the Standard Error) which is denoted $\bar  {X} \sim \mathcal  {N} \left ( \mu _0, \sigma ^2 /n \right )$.\relax }}{15}{figure.5}\protected@file@percent }
\newlabel{fig:priori1}{{5}{15}{For a given random variable $X$ which has mean $\mu _0$ and standard deviation $\sigma $, the sampling distribution of the mean of size $n$ is Normal with mean $\mu _0$ and standard deviation $\sigma /\sqrt {n}$ (the Standard Error) which is denoted $\Bar {X} \sim \mathcal {N} \brac {\mu _0, \sigma ^2 /n }$.\relax }{figure.5}{}}
\newlabel{fig:priori1@cref}{{[figure][5][]5}{[1][15][]15}}
\newlabel{fig:priori2a}{{6a}{17}{If the true mean $\mu _A$ is greater than $\mu _0$, we calculate power as the probability of observing a sample mean greater than our ``cut-off value'' $\mu _0 + 1.96 \times \sfrac {\sigma }{\sqrt {n}}$, where $\alpha = 0.05$.\relax }{subfigure.6.1}{}}
\newlabel{fig:priori2a@cref}{{[subfigure][1][6]6a}{[1][16][]17}}
\newlabel{sub@fig:priori2a}{{a}{17}{If the true mean $\mu _A$ is greater than $\mu _0$, we calculate power as the probability of observing a sample mean greater than our ``cut-off value'' $\mu _0 + 1.96 \times \sfrac {\sigma }{\sqrt {n}}$, where $\alpha = 0.05$.\relax }{subfigure.6.1}{}}
\newlabel{sub@fig:priori2a@cref}{{[subfigure][1][6]6a}{[1][16][]17}}
\newlabel{fig:priori2b}{{6b}{17}{If the true mean $\mu _A$ is less than $\mu _0$, we calculate power as the probability of observing a sample mean less than our ``cut-off value'' $\mu _0 - 1.96 \times \sfrac {\sigma }{\sqrt {n}}$, where $\alpha = 0.05$.\relax }{subfigure.6.2}{}}
\newlabel{fig:priori2b@cref}{{[subfigure][2][6]6b}{[1][16][]17}}
\newlabel{sub@fig:priori2b}{{b}{17}{If the true mean $\mu _A$ is less than $\mu _0$, we calculate power as the probability of observing a sample mean less than our ``cut-off value'' $\mu _0 - 1.96 \times \sfrac {\sigma }{\sqrt {n}}$, where $\alpha = 0.05$.\relax }{subfigure.6.2}{}}
\newlabel{sub@fig:priori2b@cref}{{[subfigure][2][6]6b}{[1][16][]17}}
\newlabel{fig:priori2c}{{6c}{17}{For a right-tailed hypothesis test, we calculate statistical power as the probability of observing a sample mean greater than our ``cut-off value'' $\mu _0 + 1.645 \times \sfrac {\sigma }{\sqrt {n}}$, where $\alpha = 0.05$.\relax }{subfigure.6.3}{}}
\newlabel{fig:priori2c@cref}{{[subfigure][3][6]6c}{[1][16][]17}}
\newlabel{sub@fig:priori2c}{{c}{17}{For a right-tailed hypothesis test, we calculate statistical power as the probability of observing a sample mean greater than our ``cut-off value'' $\mu _0 + 1.645 \times \sfrac {\sigma }{\sqrt {n}}$, where $\alpha = 0.05$.\relax }{subfigure.6.3}{}}
\newlabel{sub@fig:priori2c@cref}{{[subfigure][3][6]6c}{[1][16][]17}}
\newlabel{fig:priori2d}{{6d}{17}{For a left-tailed hypothesis test, we calculate statistical power as the probability of observing a sample mean less than our ``cut-off value'' $\mu _0 - 1.645 \times \sfrac {\sigma }{\sqrt {n}}$, where $\alpha = 0.05$.\relax }{subfigure.6.4}{}}
\newlabel{fig:priori2d@cref}{{[subfigure][4][6]6d}{[1][16][]17}}
\newlabel{sub@fig:priori2d}{{d}{17}{For a left-tailed hypothesis test, we calculate statistical power as the probability of observing a sample mean less than our ``cut-off value'' $\mu _0 - 1.645 \times \sfrac {\sigma }{\sqrt {n}}$, where $\alpha = 0.05$.\relax }{subfigure.6.4}{}}
\newlabel{sub@fig:priori2d@cref}{{[subfigure][4][6]6d}{[1][16][]17}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces When the true mean of the population is $\mu =\mu _A$, unequal to $\mu _0$, we can calculate the statistical power based on the ``cut-off values'' proposed by $\mu _0$ given in \Cref  {fig:priori1}.\relax }}{17}{figure.6}\protected@file@percent }
\newlabel{fig:priori2}{{6}{17}{When the true mean of the population is $\mu =\mu _A$, unequal to $\mu _0$, we can calculate the statistical power based on the ``cut-off values'' proposed by $\mu _0$ given in \Cref {fig:priori1}.\relax }{figure.6}{}}
\newlabel{fig:priori2@cref}{{[figure][6][]6}{[1][16][]17}}
\newlabel{fig:priori3a}{{7a}{18}{Left-tailed power calculation ($\mu _A<\mu _0$). The red shaded area is the probability of observing a sample mean less than $\mu _0 - z^*_{1 - \alpha /2} \times \sfrac {\sigma }{\sqrt {n}}$ conditional on $\mu =\mu _A$. The blue shaded area is $\beta $ and the green shaded area is $\alpha $. The use of the critical value $z^*_{1 - \alpha /2}$ v.s. $z^*_{1 - \alpha }$ depends on whether the null hypothesis is two- or one-sided.\relax }{subfigure.7.1}{}}
\newlabel{fig:priori3a@cref}{{[subfigure][1][7]7a}{[1][18][]18}}
\newlabel{sub@fig:priori3a}{{a}{18}{Left-tailed power calculation ($\mu _A<\mu _0$). The red shaded area is the probability of observing a sample mean less than $\mu _0 - z^*_{1 - \alpha /2} \times \sfrac {\sigma }{\sqrt {n}}$ conditional on $\mu =\mu _A$. The blue shaded area is $\beta $ and the green shaded area is $\alpha $. The use of the critical value $z^*_{1 - \alpha /2}$ v.s. $z^*_{1 - \alpha }$ depends on whether the null hypothesis is two- or one-sided.\relax }{subfigure.7.1}{}}
\newlabel{sub@fig:priori3a@cref}{{[subfigure][1][7]7a}{[1][18][]18}}
\newlabel{fig:priori3b}{{7b}{18}{Right-tailed power calculation ($\mu _A>\mu _0$). The red shaded area is the probability of observing a sample mean more than $\mu _0 + z^*_{1 - \alpha /2} \times \sfrac {\sigma }{\sqrt {n}}$ conditional on $\mu =\mu _A$. The blue shaded area is $\beta $ and the green shaded area is $\alpha $. The use of the critical value $z^*_{1 - \alpha /2}$ v.s. $z^*_{1 - \alpha }$ depends on whether the null hypothesis is two- or one-sided.\relax }{subfigure.7.2}{}}
\newlabel{fig:priori3b@cref}{{[subfigure][2][7]7b}{[1][18][]18}}
\newlabel{sub@fig:priori3b}{{b}{18}{Right-tailed power calculation ($\mu _A>\mu _0$). The red shaded area is the probability of observing a sample mean more than $\mu _0 + z^*_{1 - \alpha /2} \times \sfrac {\sigma }{\sqrt {n}}$ conditional on $\mu =\mu _A$. The blue shaded area is $\beta $ and the green shaded area is $\alpha $. The use of the critical value $z^*_{1 - \alpha /2}$ v.s. $z^*_{1 - \alpha }$ depends on whether the null hypothesis is two- or one-sided.\relax }{subfigure.7.2}{}}
\newlabel{sub@fig:priori3b@cref}{{[subfigure][2][7]7b}{[1][18][]18}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Power calculation for $\mu _A<\mu _0$ and $\mu _A>\mu _0$ when the population variance is known ($z$-test). If $\alpha $ is decreased, then the critical value $z^*_{1 - \alpha /2}$ (or $z^*_{1 - \alpha }$, if $H_0$ is one-sided) becomes larger which is visually shown by the red shaded area becoming smaller (smaller power). If $\alpha $ is increased, then the critical value $z^*_{1 - \alpha /2}$ (or $z^*_{1 - \alpha }$, if $H_0$ is one-sided) becomes smaller which is visually shown by the red shaded area becoming larger (larger power).\relax }}{18}{figure.7}\protected@file@percent }
\newlabel{fig:priori3}{{7}{18}{Power calculation for $\mu _A<\mu _0$ and $\mu _A>\mu _0$ when the population variance is known ($z$-test). If $\alpha $ is decreased, then the critical value $z^*_{1 - \alpha /2}$ (or $z^*_{1 - \alpha }$, if $H_0$ is one-sided) becomes larger which is visually shown by the red shaded area becoming smaller (smaller power). If $\alpha $ is increased, then the critical value $z^*_{1 - \alpha /2}$ (or $z^*_{1 - \alpha }$, if $H_0$ is one-sided) becomes smaller which is visually shown by the red shaded area becoming larger (larger power).\relax }{figure.7}{}}
\newlabel{fig:priori3@cref}{{[figure][7][]7}{[1][18][]18}}
\BKM@entry{id=11,dest={73656374696F6E2A2E3233},srcline={4}}{5765656B2034}
\BKM@entry{id=12,dest={73656374696F6E2A2E3235},srcline={8}}{742D74657374}
\@writefile{toc}{\contentsline {section}{Week 4}{19}{section*.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{$t$-test}{19}{section*.25}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The right-tailed ``cut-off values'' for a $t$-test on the mean, where $\mu _0$ is the mean under the (two-sided) null hypothesis and $s/\sqrt  {n}$ is the Standard Error. The tails are ``fatter'' when $n$ is small, and reshape to become ``thinner'' until it resembles that of the normally distributed variable with mean $\mu _0$ and standard error $\sigma /\sqrt  {n}$\relax }}{19}{figure.8}\protected@file@percent }
\newlabel{fig:priori4}{{8}{19}{The right-tailed ``cut-off values'' for a $t$-test on the mean, where $\mu _0$ is the mean under the (two-sided) null hypothesis and $s/\sqrt {n}$ is the Standard Error. The tails are ``fatter'' when $n$ is small, and reshape to become ``thinner'' until it resembles that of the normally distributed variable with mean $\mu _0$ and standard error $\sigma /\sqrt {n}$\relax }{figure.8}{}}
\newlabel{fig:priori4@cref}{{[figure][8][]8}{[1][19][]19}}
\newlabel{fig:tdist1a}{{9a}{20}{\relax }{subfigure.9.1}{}}
\newlabel{fig:tdist1a@cref}{{[subfigure][1][9]9a}{[1][20][]20}}
\newlabel{sub@fig:tdist1a}{{a}{20}{\relax }{subfigure.9.1}{}}
\newlabel{sub@fig:tdist1a@cref}{{[subfigure][1][9]9a}{[1][20][]20}}
\newlabel{fig:tdist1b}{{9b}{20}{\relax }{subfigure.9.2}{}}
\newlabel{fig:tdist1b@cref}{{[subfigure][2][9]9b}{[1][20][]20}}
\newlabel{sub@fig:tdist1b}{{b}{20}{\relax }{subfigure.9.2}{}}
\newlabel{sub@fig:tdist1b@cref}{{[subfigure][2][9]9b}{[1][20][]20}}
\newlabel{fig:tdist1c}{{9c}{20}{\relax }{subfigure.9.3}{}}
\newlabel{fig:tdist1c@cref}{{[subfigure][3][9]9c}{[1][20][]20}}
\newlabel{sub@fig:tdist1c}{{c}{20}{\relax }{subfigure.9.3}{}}
\newlabel{sub@fig:tdist1c@cref}{{[subfigure][3][9]9c}{[1][20][]20}}
\newlabel{fig:tdist1d}{{9d}{20}{\relax }{subfigure.9.4}{}}
\newlabel{fig:tdist1d@cref}{{[subfigure][4][9]9d}{[1][20][]20}}
\newlabel{sub@fig:tdist1d}{{d}{20}{\relax }{subfigure.9.4}{}}
\newlabel{sub@fig:tdist1d@cref}{{[subfigure][4][9]9d}{[1][20][]20}}
\newlabel{fig:tdist1e}{{9e}{20}{\relax }{subfigure.9.5}{}}
\newlabel{fig:tdist1e@cref}{{[subfigure][5][9]9e}{[1][20][]20}}
\newlabel{sub@fig:tdist1e}{{e}{20}{\relax }{subfigure.9.5}{}}
\newlabel{sub@fig:tdist1e@cref}{{[subfigure][5][9]9e}{[1][20][]20}}
\newlabel{fig:tdist1f}{{9f}{20}{\relax }{subfigure.9.6}{}}
\newlabel{fig:tdist1f@cref}{{[subfigure][6][9]9f}{[1][20][]20}}
\newlabel{sub@fig:tdist1f}{{f}{20}{\relax }{subfigure.9.6}{}}
\newlabel{sub@fig:tdist1f@cref}{{[subfigure][6][9]9f}{[1][20][]20}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces As the degrees of freedom increases, you can see that the shaded red area moves to the left so it appears that the shaded area is increasing. In actuality, the shaded red area is the same (representing $2.5\%$) and it appears to be changing due to changing graph shape. For small degrees of freedom, the shape of the bell curve is flat with long fat tails, and as df increases the bell curve reforms to look like that of the standard normal distribution.\relax }}{20}{figure.9}\protected@file@percent }
\newlabel{fig:tdist1}{{9}{20}{As the degrees of freedom increases, you can see that the shaded red area moves to the left so it appears that the shaded area is increasing. In actuality, the shaded red area is the same (representing $2.5\%$) and it appears to be changing due to changing graph shape. For small degrees of freedom, the shape of the bell curve is flat with long fat tails, and as df increases the bell curve reforms to look like that of the standard normal distribution.\relax }{figure.9}{}}
\newlabel{fig:tdist1@cref}{{[figure][9][]9}{[1][20][]20}}
\BKM@entry{id=13,dest={73656374696F6E2A2E3237},srcline={300}}{4D6174682065787072657373696F6E73}
\@writefile{toc}{\contentsline {subsection}{Math expressions}{21}{section*.27}\protected@file@percent }
\BKM@entry{id=14,dest={73656374696F6E2A2E3239},srcline={3}}{5765656B2036}
\BKM@entry{id=15,dest={73656374696F6E2A2E3331},srcline={7}}{436F6E74696E67656E6379207461626C657320616E6420746573747320666F7220696E646570656E64656E6365}
\@writefile{toc}{\contentsline {section}{Week 6}{23}{section*.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{Contingency tables and tests for independence}{23}{section*.31}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \relax }}{23}{table.caption.32}\protected@file@percent }
\newlabel{tab:1wk6}{{4}{23}{\relax }{table.caption.32}{}}
\newlabel{tab:1wk6@cref}{{[table][4][]4}{[1][23][]23}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces This is a $3 \times 4$ contingency table, for which the odds ratio is not as simply calculated as it was for the $2 \times 2$ contingency table.\relax }}{24}{table.caption.33}\protected@file@percent }
\newlabel{tab:2wk6}{{5}{24}{This is a $3 \times 4$ contingency table, for which the odds ratio is not as simply calculated as it was for the $2 \times 2$ contingency table.\relax }{table.caption.33}{}}
\newlabel{tab:2wk6@cref}{{[table][5][]5}{[1][24][]24}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces \relax }}{24}{table.caption.34}\protected@file@percent }
\newlabel{tab:3wk6}{{6}{24}{\relax }{table.caption.34}{}}
\newlabel{tab:3wk6@cref}{{[table][6][]6}{[1][24][]24}}
\BKM@entry{id=16,dest={73656374696F6E2A2E3337},srcline={145}}{486F6D65776F726B}
\BKM@entry{id=17,dest={73756273656374696F6E2E312E31},srcline={2}}{486F6D65776F726B2031}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Expected frequencies - it is important that the marginal frequencies are the same as in \Cref  {tab:2wk6}.\relax }}{25}{table.caption.35}\protected@file@percent }
\newlabel{tab:4wk6}{{7}{25}{Expected frequencies - it is important that the marginal frequencies are the same as in \Cref {tab:2wk6}.\relax }{table.caption.35}{}}
\newlabel{tab:4wk6@cref}{{[table][7][]7}{[1][24][]25}}
\@writefile{toc}{\contentsline {section}{Homework}{26}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Homework 1}{26}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces This graph shows the distributions from parts a and b of question 1 (homework 1), with the sampling distribution of the difference in scores overlaid. \relax }}{26}{figure.10}\protected@file@percent }
\newlabel{fig:hw1q1c}{{10}{26}{This graph shows the distributions from parts a and b of question 1 (homework 1), with the sampling distribution of the difference in scores overlaid. \relax }{figure.10}{}}
\newlabel{fig:hw1q1c@cref}{{[figure][10][]10}{[1][26][]26}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces This graph shows the sampling distribution of the difference in scores from parts a and b of question 1 (homework 1). The shaded area on the left (between the axis and zero) represents the probability that the difference is less than zero, which equates to approximately 0.41\%.\relax }}{27}{figure.11}\protected@file@percent }
\newlabel{fig:hw1q1d}{{11}{27}{This graph shows the sampling distribution of the difference in scores from parts a and b of question 1 (homework 1). The shaded area on the left (between the axis and zero) represents the probability that the difference is less than zero, which equates to approximately 0.41\%.\relax }{figure.11}{}}
\newlabel{fig:hw1q1d@cref}{{[figure][11][]11}{[1][27][]27}}
\newlabel{eq:hw1q4a}{{173}{30}{Homework 1}{equation.1.173}{}}
\newlabel{eq:hw1q4a@cref}{{[equation][173][]173}{[1][30][]30}}
\BKM@entry{id=18,dest={73756273656374696F6E2E312E32},srcline={216}}{486F6D65776F726B2032}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Homework 2}{31}{subsection.1.2}\protected@file@percent }
\newlabel{hw2q1}{{1}{31}{Homework 2}{Item.56}{}}
\newlabel{hw2q1@cref}{{[enumi][1][]1}{[1][31][]31}}
\BKM@entry{id=19,dest={73756273656374696F6E2E312E33},srcline={366}}{486F6D65776F726B2033}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The sampling distributions of the mean of $X \sim \left ( 335, 15^2\right )$ for samples of size 25, 100 and 500.\relax }}{34}{figure.12}\protected@file@percent }
\newlabel{fig:hw2q3d}{{12}{34}{The sampling distributions of the mean of $X \sim \brac {335, 15^2}$ for samples of size 25, 100 and 500.\relax }{figure.12}{}}
\newlabel{fig:hw2q3d@cref}{{[figure][12][]12}{[1][34][]34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Homework 3}{34}{subsection.1.3}\protected@file@percent }
\newlabel{eq:hw3q2c}{{238}{37}{Homework 3}{equation.1.238}{}}
\newlabel{eq:hw3q2c@cref}{{[equation][238][]238}{[1][37][]37}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The shaded area represents the power of the test for increasing values of $n$, where the random variable $\bar  {X}$ is distributed normally with standard error $400/\sqrt  {n}$ ($\alpha = 0.05$; $H_0:$ $\mu =3000$ms; $H_a: $ $\mu >3000$ms; true mean $\mu =3300$ms). As $n$ increases, the ``cut-off value'' decreases resulting in an increase of statistical power (caeteris paribus).\relax }}{38}{figure.13}\protected@file@percent }
\newlabel{fig:hw3q2c}{{13}{38}{The shaded area represents the power of the test for increasing values of $n$, where the random variable $\bar {X}$ is distributed normally with standard error $400/\sqrt {n}$ ($\alpha = 0.05$; $H_0:$ $\mu =3000$ms; $H_a: $ $\mu >3000$ms; true mean $\mu =3300$ms). As $n$ increases, the ``cut-off value'' decreases resulting in an increase of statistical power (caeteris paribus).\relax }{figure.13}{}}
\newlabel{fig:hw3q2c@cref}{{[figure][13][]13}{[1][38][]38}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces \relax }}{40}{figure.14}\protected@file@percent }
\newlabel{fig:hw3q3d}{{14}{40}{\relax }{figure.14}{}}
\newlabel{fig:hw3q3d@cref}{{[figure][14][]14}{[1][40][]40}}
\BKM@entry{id=20,dest={73756273656374696F6E2E312E34},srcline={1}}{486F6D65776F726B2034}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces \relax }}{41}{figure.15}\protected@file@percent }
\newlabel{fig:hw3q3e}{{15}{41}{\relax }{figure.15}{}}
\newlabel{fig:hw3q3e@cref}{{[figure][15][]15}{[1][40][]41}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces For the $t$-distribution with 9 degrees of freedom, a test statistic of $-4.45$ is significant at every level as the (two-sided) critical value for $\alpha = 0.002$ is $-4.297$.\relax }}{41}{figure.16}\protected@file@percent }
\newlabel{fig:hw3q4b}{{16}{41}{For the $t$-distribution with 9 degrees of freedom, a test statistic of $-4.45$ is significant at every level as the (two-sided) critical value for $\alpha = 0.002$ is $-4.297$.\relax }{figure.16}{}}
\newlabel{fig:hw3q4b@cref}{{[figure][16][]16}{[1][41][]41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Homework 4}{41}{subsection.1.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces \relax }}{42}{table.caption.39}\protected@file@percent }
\newlabel{tab:hw4q1}{{8}{42}{\relax }{table.caption.39}{}}
\newlabel{tab:hw4q1@cref}{{[table][8][]8}{[1][41][]42}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces This box plot represents the difference in scores $D = A - B$ for the data given in \Cref  {tab:hw4q1}. The five-number summary is $-15$, $-6.25$, $-1$, $4.25$, $11$ and the IQR is 10.5, thus there are no outliers. The blue diamond displays the sample mean $-0.55$, which indicates a slight skewing to the right.\relax }}{43}{figure.17}\protected@file@percent }
\newlabel{fig:hw4q1a}{{17}{43}{This box plot represents the difference in scores $D = A - B$ for the data given in \Cref {tab:hw4q1}. The five-number summary is $-15$, $-6.25$, $-1$, $4.25$, $11$ and the IQR is 10.5, thus there are no outliers. The blue diamond displays the sample mean $-0.55$, which indicates a slight skewing to the right.\relax }{figure.17}{}}
\newlabel{fig:hw4q1a@cref}{{[figure][17][]17}{[1][42][]43}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces These box plots represent the scores for the data given in \Cref  {tab:hw4q1}. The five-number summaries are ($0$, $20$, $30.5$, $41.25$, $48$) (IQR $=21.25$) and ($7$, $19$, $33$, $38$, $43$) (IQR $=19$), respectively, thus there are no outliers. The diamonds display the sample means $28.1$ and $28.65$, which indicate skewing to the left for both distributions.\relax }}{43}{figure.18}\protected@file@percent }
\newlabel{fig:hw4q1d}{{18}{43}{These box plots represent the scores for the data given in \Cref {tab:hw4q1}. The five-number summaries are ($0$, $20$, $30.5$, $41.25$, $48$) (IQR $=21.25$) and ($7$, $19$, $33$, $38$, $43$) (IQR $=19$), respectively, thus there are no outliers. The diamonds display the sample means $28.1$ and $28.65$, which indicate skewing to the left for both distributions.\relax }{figure.18}{}}
\newlabel{fig:hw4q1d@cref}{{[figure][18][]18}{[1][43][]43}}
\BKM@entry{id=21,dest={73756273656374696F6E2E312E35},srcline={259}}{486F6D65776F726B2035}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces This (centred) histogram of the data from \texttt  {anxc1} shows that it is a right-skewed distribution, with $\bar  {x}=31.1069$, $s=15.62621$, and $n=18$.\relax }}{48}{figure.19}\protected@file@percent }
\newlabel{fig:hw4q5b}{{19}{48}{This (centred) histogram of the data from \texttt {anxc1} shows that it is a right-skewed distribution, with $\bar {x}=31.1069$, $s=15.62621$, and $n=18$.\relax }{figure.19}{}}
\newlabel{fig:hw4q5b@cref}{{[figure][19][]19}{[1][47][]48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Homework 5}{48}{subsection.1.5}\protected@file@percent }
\BKM@entry{id=22,dest={73756273656374696F6E2E312E36},srcline={439}}{486F6D65776F726B2036}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces SPSS frequency table output for the proportion of residents of nursing homes in Drenthe suffering from depression prior to initiating staff training in detecting symptoms of depression.\relax }}{52}{figure.20}\protected@file@percent }
\newlabel{tab:hw5q5b}{{20}{52}{SPSS frequency table output for the proportion of residents of nursing homes in Drenthe suffering from depression prior to initiating staff training in detecting symptoms of depression.\relax }{figure.20}{}}
\newlabel{tab:hw5q5b@cref}{{[figure][20][]20}{[1][52][]52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6}Homework 6}{52}{subsection.1.6}\protected@file@percent }
